{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing notebook\n"
     ]
    }
   ],
   "source": [
    "print(\"testing notebook\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><h1>Monday April 8th</h1></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h3>Tutorials on YouTube</h3>\n",
    "\n",
    "Follow these tutorials to enhance your skills:\n",
    "- **Working with Sequence Data**: Learn the basics of handling genomic sequences.\n",
    "- **Searching for Information & FastQ Files**: Discover how to find relevant scientific data and work with FastQ files.\n",
    "\n",
    "## <h3>Useful Links</h3>\n",
    "- [Tutorial on Sequence Data](https://www.youtube.com/watch?v=dYvgbgEjwLs)\n",
    "- [Tutorial on Searching Information and FastQ Files](https://www.youtube.com/watch?v=2lH4uxHCeJA&list=PLNteKiuWD0-L6zFGNHNSjYYJA3xljeu2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastq files\n",
    "- most of the time sequencing data comes back as a fastq file\n",
    "- First line\n",
    "    - ID is indicated by an '@' symbol\n",
    "        - encodes spot on the plate where the cluster of fragments were\n",
    "- Second line\n",
    "    - DNA sequence\n",
    "- Third line \n",
    "    - Record ID\n",
    "        - starts with '+' sign\n",
    "- Fourth line\n",
    "    - quality score\n",
    "        - encodes information about the probability of an error of that read \n",
    "        - each character refers to a quality score\n",
    "    -  Phred scores\n",
    "        - tells how confident the machine was to identify the correct base\n",
    "            - higher the PHRED score = highly probability that it is correct. \n",
    "        - each score is associated with a character\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes!\n",
      "The DNA sequence has a GC content of 51.724137931034484 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.gcContent(DNA)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining DNA sequence Content with basic python \n",
    "\n",
    "DNA = 'GCTGACTGATCGATGCATGCTAGCTAGCT'\n",
    "\n",
    "#HOW DO YOU FIND IF THE SEQUENCE HAS A PARTICULAR SUBSEQUENCE?\n",
    "\n",
    "'CG' in DNA\n",
    "\n",
    "#Answer will be true\n",
    "\n",
    "if 'CG' in DNA:print('yes!')\n",
    "    #Reminder that if statements require a colon\n",
    "\n",
    "\n",
    "DNA.count('AT')\n",
    "\n",
    "#AT is 5\n",
    "\n",
    "#Computing GC content with python\n",
    "\n",
    "def gcContent(DNA):\n",
    "    totalC = DNA.count('C')\n",
    "    totalG = DNA.count('G')\n",
    "    gcContent = 100*(totalC + totalG)/len(DNA)\n",
    "    return gcContent\n",
    "\n",
    "print(\"The DNA sequence has a GC content of\", gcContent(DNA), \"%\")\n",
    "       \n",
    "gcContent      \n",
    "\n",
    "#answer is 51.724137931034484 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# re stands for Regular Expression\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print the number of 'ATG' occurrences\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATG\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m occurrences is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(matches_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m matches \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfinditer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATG\u001b[39m\u001b[38;5;124m'\u001b[39m, DNA)\n\u001b[1;32m     12\u001b[0m matches_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(matches) \u001b[38;5;66;03m# Convert iterator to a list to check its length\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matches_list' is not defined"
     ]
    }
   ],
   "source": [
    "#Loop through a DNA sequence and find a pattern\n",
    "\n",
    "DNA = 'GCTGACTGATCGATGCATGCTAGCTAGATGCTATG'\n",
    "\n",
    "import re\n",
    "# re stands for Regular Expression\n",
    "\n",
    "# Print the number of 'ATG' occurrences\n",
    "print(f\"The number of 'ATG' occurrences is: {len(matches_list)}\")\n",
    "\n",
    "matches = re.finditer('ATG', DNA)\n",
    "matches_list = list(matches) # Convert iterator to a list to check its length\n",
    "if matches_list: \n",
    "    for match in matches_list:\n",
    "        print(f\"An 'ATG' match is located between {match.start()} and {match.end()}\")\n",
    "else:\n",
    "    print(\"No 'ATG' matches found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><h1>Wednesday April 10th</h1></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A beginner's bioinformatics guide for single-cell RNAseq data analysis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Reverse compliment of a sequence](https://www.youtube.com/watch?v=t9C1g6ld-ng&list=PLNteKiuWD0-L6zFGNHSNjYYJA3xljIeu2&index=11)\n",
    "- [Introduction to fastq files](https://www.youtube.com/watch?v=9bN4rWPecmw&t=53s)\n",
    "- [fasta vs fastq](https://www.youtube.com/watch?v=xYEre9DtIqA&t=1s)\n",
    "- [Galaxy training](https://training.galaxyproject.org/training-material/topics/introduction/tutorials/galaxy-intro-101/tutorial.html)\n",
    "\n",
    "\n",
    "Sites to investigate \n",
    "- [parsing Fastq files with Biopython SeqIO moedule](https://www.youtube.com/watch?v=mDEwKw0w1Qk)\n",
    "- [intro to Biopython SeqIO module: Reading Fasta files](https://www.youtube.com/watch?v=Y9POfa_PH-M)\n",
    "- [setup RNA-seq pipeline from scratch: fastq (reads) to counts](https://www.youtube.com/watch?v=lG11JjovJHE&t=1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the reverse compliment of a sequence\n",
    "\n",
    "def complement(DNA):\n",
    "    comp = {'A': 'T', 'C':'G', 'G':'C', 'T':'A'}\n",
    "    compDNA = ''\n",
    "    for b in DNA:\n",
    "        compDNA += comp[b]\n",
    "    return compDNA\n",
    "def reverse (DNA):\n",
    "    return DNA[::-1]\n",
    "\n",
    "def reverse_complement(DNA):\n",
    "    compDNA = complement(DNA)\n",
    "    compDNA = complement(DNA)\n",
    "    revCompDNA = reverse(compDNA)\n",
    "    return revCompDNA \n",
    "\n",
    "DNA = input(\"Please enter a DNA sequence.\")\n",
    "print(\"you have entered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fasta files\n",
    "- used to store sequenes (either amino acid or nucleic acid)\n",
    "    - if its a nuclear acid sequence the file could be .fna\n",
    "    - if its a amino acid sequence the file could be .faa\n",
    "- each amino acid is represented by one letter code\n",
    "- divided into parts\n",
    "    - header \n",
    "        - starts with a '>' symbol\n",
    "    - sequence\n",
    "        - can have multiple sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Intro to Galaxy</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><p style=\"color:#7393B3;\">Familiarize yourself with the basics of Galaxy</p></h3>  \n",
    "\n",
    "- Learn how to obtain data from external sources\n",
    "- Learn how to run tools\n",
    "- Learn how histories work\n",
    "- Learn how to create a workflow\n",
    "- Learn how to share your work\n",
    "\n",
    "\n",
    "<h3><p style=\"color:#7393B3;\">Question</p></h3>\n",
    "\n",
    "Which coding exon has the highest number of single nucleotide polymorphisms (SNPs) on human chromosome 22?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><p style=\"color: #7393B3;\">Upload Data and Start Analysis</p></h3>\n",
    "<p style=\"color:;\">Upload the data and click start to create new datasets.</p>\n",
    "<p style=\"color:;\">You can rename the datasets afterwards.</p>\n",
    "\n",
    "<h3><p style=\"color: #7393B3;\">Find Intersections in BED (Side Panel)</p></h3>\n",
    "<p style=\";\">Use the BED tools \"intersect intervals\" function.</p>\n",
    "<p><p style=\"color: pink;\">This will intersect dataset A with dataset B.</p>\n",
    "\n",
    "<h3><p style=\"color: #7393B3;\">Analysis Steps</h3>\n",
    "<h4>1. Intersect Exons with SNPs</h4>\n",
    "<p style=\"color: pink;\">This step finds overlapping regions between exons and SNPs.</p>\n",
    "\n",
    "<h4>2. Strandedness-Based Calculations </h4>\n",
    "<p style=\"color: teal;\">Analyze overlaps based on the strand orientation (positive or negative) of the features (if applicable).</p>\n",
    "  <p style=\"color: pink;\">This step considers overlaps on either strand.</p>\n",
    "\n",
    "\n",
    "  <h4>3. What should be written to the output file?</h4>\n",
    "   <p style=\"color: teal;\">\"Write the original entry in b......\"</p>\n",
    "\n",
    "  <h4>4. Click Run Tool</h4> \n",
    "   <p style=\"color: pink;\">This will create a new dataset\n",
    "   <br>\n",
    "   This will return the exon and snp information\n",
    "   <br>\n",
    "   Easy to see how many snps per exons it has\n",
    "   <br>\n",
    "   Count lines with unique line exon Ids \n",
    "   <br>\n",
    "   \n",
    "   </p>  \n",
    "\n",
    "\n",
    "\n",
    "<h3><p style=\"color: #7393B3;\"> Find Datamash (Side Panel)</p></h3>\n",
    "\n",
    "<h4>1. Group by feilds</h4>\n",
    "<p style=\"color: teal;\">\"4\"</p>\n",
    "\n",
    "  <p style=\"color: pink;\">what is the column number you are interested in? In this case it would be column 4 because this is where the exon ID is</p>\n",
    "\n",
    "  <h4>2. Operation to perform on each group Type:</h4>\n",
    "<p style=\"color: teal;\">\"count unique values\"</p>\n",
    "<h4>3. On column:</h4>\n",
    "<p style=\"color: teal;\">\"10\"</p>\n",
    "\n",
    "  <p style=\"color: pink;\">This is where the SNP IDs are</p>\n",
    "\n",
    "<h4>4. Run tool:</h4>\n",
    "\n",
    "<p style=\"color: pink;\">This will return a new dataset that contains exon ID and the count of unique snps within the exon. View this new data sheet</p>\n",
    "\n",
    "\n",
    "\n",
    "<h3><p style=\"color: #7393B3;\"> Find Text Manipulation (Side Panel)</p></h3>\n",
    "\n",
    "<h4>1. Sort:</h4>\n",
    "\n",
    "<h4>2. On column:</h4>\n",
    "<p style=\"color: teal;\">\"Column 2\"</p>\n",
    "\n",
    "<h4>3. With flavor:</h4>\n",
    "<p style=\"color: teal;\">\"Desending order\"</p>\n",
    "\n",
    "\n",
    "<p style=\"color: pink;\">This will return a new dataset that contains exon ID and the count of unique snps within the exon in descending order. View this new data sheet. In this dataset the most number of SNPs is 27 on ENST00000253255.7_cds_0_0_chr22_46256561_r </p>\n",
    "\n",
    "\n",
    "<h3><p style=\"color: #7393B3;\"> Find Text Manipulation (Side Panel)</p></h3>\n",
    "\n",
    "<h4>1. Select first:</h4>\n",
    "<p style=\"color: teal;\">\"5\"</p>\n",
    "\n",
    "\n",
    "<p style=\"color: pink;\">This will return a new dataset that contains exon ID with the highest number of SNPS in desending order. Next step is to visualze this in a genome browser. For this we need the start and end coordinates. Which is located in the original files </p>\n",
    "\n",
    "\n",
    "<h3><p style=\"color: #7393B3;\"> Find Join, Subtract, and Group (Side Panel)</p></h3>\n",
    "\n",
    "<h4>1. Compare two datasets:</h4>\n",
    "<p style=\"color: teal;\">\"Compare exons (insert file)\"</p>\n",
    "<h4>2. Using column</h4>\n",
    "<p style=\"color: teal;\">\"column 4\"</p>\n",
    "<h4>3. Against</h4>\n",
    "<p style=\"color: teal;\">\"Select first on data 5 (insert file)\"</p>\n",
    "<p style=\"color: teal;\">\"column 1\"</p>\n",
    "<h4>4. To find </h4>\n",
    "<p style=\"color: teal;\">\"Matching rows of 1st dataset\"</p>\n",
    "<h4>5. Run Tool </h4>\n",
    "\n",
    "<p style=\"color: pink;\">This will return a new dataset that contains exon ID with the highest number of SNPS in desending order. AND the start and end sites. \n",
    "<br> Next step is to identify which version of the genome we want to render the data \n",
    "<br>Tell the data that it is derived from human\n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "<h3><p style=\"color: #7393B3;\"> Find database (History Panel under title)</p></h3>\n",
    "\n",
    "<h4>1. Click on the question mark </h4>\n",
    "<h4>2. Scroll to \"Database/Build\"</h4>\n",
    "<p style=\"color: teal;\">\"Select human\"</p>\n",
    "\n",
    "\n",
    "<p style=\"color: pink;\">This will now change the \"?\" to \"hg38\"\n",
    "\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "This should display something called \n",
    "'display at UCSC main' where main is a hyperlink to a genome browser to see exon of interest based on the coordinates you have. This should return information about the exon. \n",
    "\n",
    "\n",
    "This is not working out, moving on.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"color: pink;\">\n",
    "What you have created on the history panel is essential a workflow, and you want to do the same analysis on a different set of data. \n",
    "<br>You can extract workflow of this history by clicking the gear icon</p>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><h1>Wednesday April 11th</h1></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Parsing Fastq files with Biopython SeqIO moedule</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to process a fastq file using a Biopython SeqIO module\n",
    "\n",
    "you can use this to identify peaks in the genome where heatshock factor binds and motif finding and what it looks like.\n",
    "\n",
    "**there are some other tools like skewer or fastq trimmer that you will most likely use instead. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Setup RNA-seq pipeline from scratch: fastq (reads) to counts </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"workflow.png\" alt=\"Example Image\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "you can identify transcripts by mapping reads onto the genome\n",
    "\n",
    "well annotated genomes like human genome we can base RNA seq analysis based on existing annotioation and references available \n",
    "\n",
    "used rna seq data allele specific expression and disease assocated SNPs and gene fushions in cancer\n",
    "\n",
    "depending on the research goal the analysis can be selected and appropriately applied \n",
    "\n",
    "Schematic to process RNA seq reads\n",
    "\n",
    "First step \n",
    "- perform quality control of reads that are in fastq files\n",
    "    - use tools like \n",
    "        - fastq screen\n",
    "         - fastq c \n",
    "\n",
    "    - goal is to remove bases that are poor quality and adaptor sequences \n",
    "        - adapter sequences are ligated to the ends of DNA fragment to faciliate their amplification and sequencings and are needed for processing, but these are not a part of the original DNA/ RNA sample and contain no relevant biological information\n",
    "\n",
    "step 2\n",
    "- trimming step\n",
    "- tool\n",
    "    - timmermatic\n",
    "    - cut adapt \n",
    "\n",
    "step 3\n",
    "- map the reads to a genome or a transcriptome\n",
    "\n",
    "- mapping to a genome\n",
    "    - need to use splicedware aligners\n",
    "        - RNA seq reads are matured from mature mRNA which includes exons only and no introns so if you try to align this to the reference sequence which is not splicedware, it would try to map these rna seq reads to references containing intron wihch are not preseent in your RNA seq reads. thus, it will not be aligned. you need an aligner that will identify the downstream exons \n",
    "        - software\n",
    "            - star\n",
    "            - tophat 2\n",
    "            - high cycle\n",
    "\n",
    "- mapping to a transcriptome \n",
    "    - this tool does not report alignments, but associate a read to a given transcript for quantification. the output from these are \"Counts\"\n",
    "    -splicedunaware aligner\n",
    "        - software \n",
    "            - bowtie 2\n",
    "            - vwa\n",
    "    - quasi mapper\n",
    "        - software\n",
    "            - salmon\n",
    "            - kallistro\n",
    "\n",
    "\n",
    "\n",
    "Step 4\n",
    "\n",
    "Spliced aware and unaware aligners need to be further processed and quantifid to generate counts \n",
    "- softwards\n",
    "    - RSEM\n",
    "    - eXpress\n",
    "\n",
    "\n",
    "Step 5\n",
    "\n",
    "Once you have a count file, you can do a downstream analysis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"workflow 2.png\" alt=\"Example Image\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><h1>Monday April 22-26</h1></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sequence Data Processing\n",
    "FASTQ files obtained from sequencing facility are processed using <a href=\"http://www.usegalaxy.org\">Galaxy</a> and in-house python scripts to ultimately obtain tabular files that map Tn sequencing reads to individual sequence sites. \n",
    "\n",
    "### <span style=\"color: #40E0D0;\">FASTQ: The raw sequencing reads</span>\n",
    "1. To download FASTQs from the <a href=\"https://www.ncbi.nlm.nih.gov/sra\">Sequence Reads Archive add Accession ID: <b>PRJNA558044</b></a>\n",
    "    - This refers to the project ID not the individual sing sequencing ID. \n",
    "2. Select <b>\"Fastq\"</b>\n",
    "    - SRA section shows how many experiments (51)\n",
    "3. Select <b>\"Send results to Run selector\"</b>\n",
    "    - <img src=\"Fastq file from SRA.png\" alt=\"Example Image\" style=\"width: 200px;\"/>\n",
    "\n",
    "4. Select all and compute into \"Galaxy\"    \n",
    "\n",
    "4. Download the files from <a href = \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6934316/\">paper's github</a>  (19 files)\n",
    "    - __Galaxy-Workflow-TnSeq.ga__ - The workflow used in Galaxy to process the FASTQ files into SAM files. \n",
    "    - __Galaxy-SampleBarcodes.txt__ - An input for the Galaxy workflow that contains the six sample barcodes used to split the raw FASTQ from the pooled sample into the FASTQs for individual samples. \n",
    "        - __Galaxy-TransposonBarcodes.txt__ - An input for the Galaxy workflow that contains the six transposon barcodes used to split each individual sample FASTQ by transposon construct. \n",
    "    - __Filter1.txt__ - An input for the Galaxy workflow used to get rid of unmatched reads. \n",
    "    - __Filter2.txt__ - An input for the Galaxy workflow used to get rid of unmatched reads.\n",
    "    - __Filter3.txt__ - An input for the Galaxy workflow used to get rid of unmatched reads.\n",
    "    - __*.fasta__ - A chromosome nucleotide fasta for the genome you are mapping to. See paper methods for the NCBI accession numbers for the strains used.  \n",
    "    - __sam_to_tabular.py__ - A python script that converts all SAM files in the directory to tab-delimited hop count files. \n",
    "\n",
    "#### <span style=\"color: #40E0D0;\">Process</span>\n",
    "1. Sign into <a href=\"http://www.usegalaxy.org\">Galaxy</a> and upload FASTQ, workflow, barcodes, filters, and fasta(s).\n",
    "   - There is an option to get SRA files within galaxy\n",
    "2. Search for accesson ID (PRJNA55804)in Sequence Reads Archive\n",
    "3. Under \"File Type\" click Fastq\n",
    "4. Next to \"View results as an expanded interactive table using the RunSelector\" \n",
    "5. Select all and under computing select \"Galaxy\"\n",
    "6. <img src=\"Fastq file from SRA.png\" alt=\"Example Image\" style=\"width: 100px;\"/> \n",
    "\n",
    "\n",
    "7. Based on the paper's method section <a ref =\"https://www.ncbi.nlm.nih.gov/genome\"> find fasta files </a> using sequence Accession IDs:\n",
    "    - You can use each accession ID for the specific strains mentioned \n",
    "        1.  <a ref = \"https://www.ncbi.nlm.nih.gov/nuccore/NC_007795.1/\"> NC_007795.1 (parent strain) </a>\n",
    "        2. NC_010079.1 (USA300-TCH1516)\n",
    "        3. NC_002953.3 (MSSA476)\n",
    "        4. NC_003929.1 (MW2) // new : NC_003923.1\n",
    "        5. NC_002952.2 (MRSA252)\n",
    "\n",
    "8. Enter each accession ID one at a time in the search bar.\n",
    "\n",
    "    - After searching, click on the link to the specific genome.\n",
    "    - On the genome summary page, look for a link to download the genome in FASTA format. \n",
    "    - This is typically under a section labeled \"FTP\" or directly available as a \"Download\" button with options where you can select \"FASTA.\"\n",
    "\n",
    "9. Verify and Download:\n",
    "\n",
    "    Ensure you're downloading the right files by checking the strain and version number.\n",
    "    Download the file to your local machine.\n",
    "\n",
    "10. Upload fasta files to Galaxy:\n",
    "  \n",
    "11. Go to tab workflow, Upload Galaxy-workflow-tnSeq.ga from Walker github Repo files\n",
    "12. Click on Run...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Upload sequencing data : <b>SRR9899156</b>\n",
    "2. Sample Barcode:  <b>Galaxy-SampleBarcodes.txt</b>\n",
    "3. Tn Barcodes: <b>Galaxy-TransposonBarcode.txt</b>\n",
    "4. Filter 1: <b>Filter 1</b>\n",
    "5. Filter 2: <b>Filter 2</b>\n",
    "6. Filter 3: <b>Filter 3</b>\n",
    "7. FASTA file for genome\n",
    "    - example: <b>NC_007795.1.fasta</b>\n",
    "8. Follow the prompts to select the appropriate inputs. \n",
    "If the FASTQ file has samples from multiple genomes, run the workflow once with each fasta file and only save the appropriate SAM files.\n",
    "9. Download the resulting SAM files into a directory containing the sam_to_tabular.py script. \n",
    "10. Sometimes in life, the files don't provide the information you are looking for.\n",
    "    - download the fasta files <a ref = \"https://www.ncbi.nlm.nih.gov/nuccore/NC_007795.1/#feature_NC_007795.1\"> again </a> \n",
    "\n",
    "    - under the send to \n",
    "    - chose \"coding sequence\"\n",
    "    - chose \"FASTA nucleotide\"\n",
    "    - create file\n",
    "11. Download it to one folder\n",
    "12. Upload the multi-fasta files into galaxy. Tell it to upload it in the fasta format\n",
    "13. Run the workflow again to get SAM Files\n",
    "\n",
    "\n",
    "\n",
    " ## start here\n",
    "\n",
    "### <span style=\"color: #40E0D0;\">SAM FILES to Tabular</span>\n",
    "1. Run the sam_to_tabular.py script `python sam_to_tabular.py`\n",
    "    1. The Script is in the <a ref=\"https://github.com/SuzanneWalkerLab/5SATnSeq/blob/master/sam_to_tabular.py\">Walker github repo</a>\n",
    "    2. I downloaded this file into my Repo and synced the changes\n",
    "        -  You need to ensure that this script is on your Galaxy server or your local environment where you're working with the Galaxy interface.\n",
    "        - You usually would use a command like python sam_to_tabular.py in a command line interface \n",
    "\n",
    "\n",
    "        - <span style=\"color: #FFC4CA;\">Why Convert from SAM to Tabular?</span>\n",
    "            - SAM files: good for storing alignment data, but clunky for analysis.\n",
    "            - Tabular format: Easier to read, manipulate (filtering, sorting), and visualize (charts, graphs).\n",
    "            - This Python script is presumably designed to read SAM files and convert them into a tabular format (.tabular).\n",
    "            - ou need to ensure that this script is on your Galaxy server or your local environment where you're working with the Galaxy interface\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run sam_to_tabular(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# GOAL: reconstruct the hopcount tool we use in Tufts Galaxy (galaxy.med.tufts.edu) that is not present on usegalaxy.org.  \n",
    "\n",
    "import glob \n",
    "\n",
    "sams = glob.glob('~/Users/tailob/Dropbox/Breeya_rotation/Files/multi_fasta_SAM/3389_SAM')\n",
    "print(len(sams))\n",
    "\n",
    "\n",
    "for s in sams:\n",
    "\tdatadict = {}\n",
    "\tfor line in open(s,'r').readlines():\n",
    "\t\tif not line.startswith('@') and not line.startswith('/'):\n",
    "\t\t\tinfo = line.split('\\t')\n",
    "\t\t\tflag = info[1]; ref = info[2]; site = int(info[3]); seq = info[9]\n",
    "\t\t\tif flag == '0': \n",
    "\t\t\t\tif (ref,site) in datadict: \n",
    "\t\t\t\t\tdatadict[(ref,site)][0]+=1\n",
    "\t\t\t\telse: datadict[(ref,site)]=[1,0]\n",
    "\t\t\telif flag == '16':\n",
    "\t\t\t\tif (ref,site+15) in datadict: \n",
    "\t\t\t\t\tdatadict[(ref,site+15)][1]+=1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tdatadict[(ref,site+15)]=[0,1]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\toutput = open(s[:-3]+'tabular','w')\n",
    "\toutput.write('Reference\\tPosition\\tLocus\\tGene\\tPlusCount\\tMinusCount\\tTotalCount\\tProduct\\tProteinID\\tNote\\tSequence\\n')\n",
    "\tdatakeys = datadict.keys()\n",
    "\t#datakeys.sort(key=lambda x: x[1])\n",
    "\tfor k in datakeys: \n",
    "\t\toutput.write(k[0]+'\\t'+str(k[1])+'\\t\\t\\t')\n",
    "\t\toutput.write('%i\\t%i\\t%i\\t\\t\\t\\t\\n' %(datadict[k][0],datadict[k][1],datadict[k][0]+datadict[k][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Files/multi_fasta_SAM/4483_SAM/Sample2_blunt.sam', './Files/multi_fasta_SAM/4483_SAM/Sample6_dual.sam', './Files/multi_fasta_SAM/4483_SAM/Sample1_erm.sam', './Files/multi_fasta_SAM/4483_SAM/Sample3_tuf.sam', './Files/multi_fasta_SAM/4483_SAM/Sample6_cap.sam', './Files/multi_fasta_SAM/4483_SAM/Sample1_pen.sam', './Files/multi_fasta_SAM/4483_SAM/Sample2_tuf.sam', './Files/multi_fasta_SAM/4483_SAM/Sample4_blunt.sam', './Files/multi_fasta_SAM/4483_SAM/Sample3_blunt.sam', './Files/multi_fasta_SAM/4483_SAM/Sample2_erm.sam', './Files/multi_fasta_SAM/4483_SAM/Sample3_pen.sam', './Files/multi_fasta_SAM/4483_SAM/Sample4_cap.sam', './Files/multi_fasta_SAM/4483_SAM/Sample5_blunt.sam', './Files/multi_fasta_SAM/4483_SAM/Sample1_dual.sam', './Files/multi_fasta_SAM/4483_SAM/Sample2_pen.sam', './Files/multi_fasta_SAM/4483_SAM/Sample3_erm.sam', './Files/multi_fasta_SAM/4483_SAM/Sample5_cap.sam', './Files/multi_fasta_SAM/4483_SAM/Sample1_tuf.sam', './Files/multi_fasta_SAM/4483_SAM/Sample4_tuf.sam', './Files/multi_fasta_SAM/4483_SAM/Sample6_erm.sam', './Files/multi_fasta_SAM/4483_SAM/Sample6_blunt.sam', './Files/multi_fasta_SAM/4483_SAM/Sample5_tuf.sam', './Files/multi_fasta_SAM/4483_SAM/Sample6_pen.sam', './Files/multi_fasta_SAM/4483_SAM/Sample1_cap.sam', './Files/multi_fasta_SAM/4483_SAM/Sample4_dual.sam', './Files/multi_fasta_SAM/4483_SAM/Sample5_dual.sam', './Files/multi_fasta_SAM/4483_SAM/Sample1_blunt.sam', './Files/multi_fasta_SAM/4483_SAM/Sample3_cap.sam', './Files/multi_fasta_SAM/4483_SAM/Sample3_dual.sam', './Files/multi_fasta_SAM/4483_SAM/Sample2_dual.sam', './Files/multi_fasta_SAM/4483_SAM/Sample5_erm.sam', './Files/multi_fasta_SAM/4483_SAM/Sample4_pen.sam', './Files/multi_fasta_SAM/4483_SAM/Sample6_tuf.sam', './Files/multi_fasta_SAM/4483_SAM/Sample2_cap.sam', './Files/multi_fasta_SAM/4483_SAM/Sample5_pen.sam', './Files/multi_fasta_SAM/4483_SAM/Sample4_erm.sam', './Files/multi_fasta_SAM/3673_SAM/Sample2_blunt.sam', './Files/multi_fasta_SAM/3673_SAM/Sample6_dual.sam', './Files/multi_fasta_SAM/3673_SAM/Sample1_erm.sam', './Files/multi_fasta_SAM/3673_SAM/Sample3_tuf.sam', './Files/multi_fasta_SAM/3673_SAM/Sample6_cap.sam', './Files/multi_fasta_SAM/3673_SAM/Sample1_pen.sam', './Files/multi_fasta_SAM/3673_SAM/Sample2_tuf.sam', './Files/multi_fasta_SAM/3673_SAM/Sample4_blunt.sam', './Files/multi_fasta_SAM/3673_SAM/Sample3_blunt.sam', './Files/multi_fasta_SAM/3673_SAM/Sample2_erm.sam', './Files/multi_fasta_SAM/3673_SAM/Sample3_pen.sam', './Files/multi_fasta_SAM/3673_SAM/Sample4_cap.sam', './Files/multi_fasta_SAM/3673_SAM/Sample5_blunt.sam', './Files/multi_fasta_SAM/3673_SAM/Sample1_dual.sam', './Files/multi_fasta_SAM/3673_SAM/Sample2_pen.sam', './Files/multi_fasta_SAM/3673_SAM/Sample3_erm.sam', './Files/multi_fasta_SAM/3673_SAM/Sample5_cap.sam', './Files/multi_fasta_SAM/3673_SAM/Sample1_tuf.sam', './Files/multi_fasta_SAM/3673_SAM/Sample4_tuf.sam', './Files/multi_fasta_SAM/3673_SAM/Sample6_erm.sam', './Files/multi_fasta_SAM/3673_SAM/Sample6_blunt.sam', './Files/multi_fasta_SAM/3673_SAM/Sample5_tuf.sam', './Files/multi_fasta_SAM/3673_SAM/Sample6_pen.sam', './Files/multi_fasta_SAM/3673_SAM/Sample1_cap.sam', './Files/multi_fasta_SAM/3673_SAM/Sample4_dual.sam', './Files/multi_fasta_SAM/3673_SAM/Sample5_dual.sam', './Files/multi_fasta_SAM/3673_SAM/Sample1_blunt.sam', './Files/multi_fasta_SAM/3673_SAM/Sample3_cap.sam', './Files/multi_fasta_SAM/3673_SAM/Sample3_dual.sam', './Files/multi_fasta_SAM/3673_SAM/Sample2_dual.sam', './Files/multi_fasta_SAM/3673_SAM/Sample5_erm.sam', './Files/multi_fasta_SAM/3673_SAM/Sample4_pen.sam', './Files/multi_fasta_SAM/3673_SAM/Sample6_tuf.sam', './Files/multi_fasta_SAM/3673_SAM/Sample2_cap.sam', './Files/multi_fasta_SAM/3673_SAM/Sample5_pen.sam', './Files/multi_fasta_SAM/3673_SAM/Sample4_erm.sam', './Files/multi_fasta_SAM/3936_SAM/Sample2_blunt.sam', './Files/multi_fasta_SAM/3936_SAM/Sample6_dual.sam', './Files/multi_fasta_SAM/3936_SAM/Sample1_erm.sam', './Files/multi_fasta_SAM/3936_SAM/Sample3_tuf.sam', './Files/multi_fasta_SAM/3936_SAM/Sample6_cap.sam', './Files/multi_fasta_SAM/3936_SAM/Sample1_pen.sam', './Files/multi_fasta_SAM/3936_SAM/Sample2_tuf.sam', './Files/multi_fasta_SAM/3936_SAM/Sample4_blunt.sam', './Files/multi_fasta_SAM/3936_SAM/Sample3_blunt.sam', './Files/multi_fasta_SAM/3936_SAM/Sample2_erm.sam', './Files/multi_fasta_SAM/3936_SAM/Sample3_pen.sam', './Files/multi_fasta_SAM/3936_SAM/Sample4_cap.sam', './Files/multi_fasta_SAM/3936_SAM/Sample5_blunt.sam', './Files/multi_fasta_SAM/3936_SAM/Sample1_dual.sam', './Files/multi_fasta_SAM/3936_SAM/Sample2_pen.sam', './Files/multi_fasta_SAM/3936_SAM/Sample3_erm.sam', './Files/multi_fasta_SAM/3936_SAM/Sample5_cap.sam', './Files/multi_fasta_SAM/3936_SAM/Sample1_tuf.sam', './Files/multi_fasta_SAM/3936_SAM/Sample4_tuf.sam', './Files/multi_fasta_SAM/3936_SAM/Sample6_erm.sam', './Files/multi_fasta_SAM/3936_SAM/Sample6_blunt.sam', './Files/multi_fasta_SAM/3936_SAM/Sample5_tuf.sam', './Files/multi_fasta_SAM/3936_SAM/Sample6_pen.sam', './Files/multi_fasta_SAM/3936_SAM/Sample1_cap.sam', './Files/multi_fasta_SAM/3936_SAM/Sample4_dual.sam', './Files/multi_fasta_SAM/3936_SAM/Sample5_dual.sam', './Files/multi_fasta_SAM/3936_SAM/Sample1_blunt.sam', './Files/multi_fasta_SAM/3936_SAM/Sample3_cap.sam', './Files/multi_fasta_SAM/3936_SAM/Sample3_dual.sam', './Files/multi_fasta_SAM/3936_SAM/Sample2_dual.sam', './Files/multi_fasta_SAM/3936_SAM/Sample5_erm.sam', './Files/multi_fasta_SAM/3936_SAM/Sample4_pen.sam', './Files/multi_fasta_SAM/3936_SAM/Sample6_tuf.sam', './Files/multi_fasta_SAM/3936_SAM/Sample2_cap.sam', './Files/multi_fasta_SAM/3936_SAM/Sample5_pen.sam', './Files/multi_fasta_SAM/3936_SAM/Sample4_erm.sam', './Files/multi_fasta_SAM/3389_SAM/Sample2_blunt.sam', './Files/multi_fasta_SAM/3389_SAM/Sample6_dual.sam', './Files/multi_fasta_SAM/3389_SAM/Sample1_erm.sam', './Files/multi_fasta_SAM/3389_SAM/Sample3_tuf.sam', './Files/multi_fasta_SAM/3389_SAM/Sample6_cap.sam', './Files/multi_fasta_SAM/3389_SAM/Sample1_pen.sam', './Files/multi_fasta_SAM/3389_SAM/Sample2_tuf.sam', './Files/multi_fasta_SAM/3389_SAM/Sample4_blunt.sam', './Files/multi_fasta_SAM/3389_SAM/Sample3_blunt.sam', './Files/multi_fasta_SAM/3389_SAM/Sample2_erm.sam', './Files/multi_fasta_SAM/3389_SAM/Sample3_pen.sam', './Files/multi_fasta_SAM/3389_SAM/Sample4_cap.sam', './Files/multi_fasta_SAM/3389_SAM/Sample5_blunt.sam', './Files/multi_fasta_SAM/3389_SAM/Sample1_dual.sam', './Files/multi_fasta_SAM/3389_SAM/Sample2_pen.sam', './Files/multi_fasta_SAM/3389_SAM/Sample3_erm.sam', './Files/multi_fasta_SAM/3389_SAM/Sample5_cap.sam', './Files/multi_fasta_SAM/3389_SAM/Sample1_tuf.sam', './Files/multi_fasta_SAM/3389_SAM/Sample4_tuf.sam', './Files/multi_fasta_SAM/3389_SAM/Sample6_erm.sam', './Files/multi_fasta_SAM/3389_SAM/Sample6_blunt.sam', './Files/multi_fasta_SAM/3389_SAM/Sample5_tuf.sam', './Files/multi_fasta_SAM/3389_SAM/Sample6_pen.sam', './Files/multi_fasta_SAM/3389_SAM/Sample1_cap.sam', './Files/multi_fasta_SAM/3389_SAM/Sample4_dual.sam', './Files/multi_fasta_SAM/3389_SAM/Sample5_dual.sam', './Files/multi_fasta_SAM/3389_SAM/Sample1_blunt.sam', './Files/multi_fasta_SAM/3389_SAM/Sample3_cap.sam', './Files/multi_fasta_SAM/3389_SAM/Sample3_dual.sam', './Files/multi_fasta_SAM/3389_SAM/Sample2_dual.sam', './Files/multi_fasta_SAM/3389_SAM/Sample5_erm.sam', './Files/multi_fasta_SAM/3389_SAM/Sample4_pen.sam', './Files/multi_fasta_SAM/3389_SAM/Sample6_tuf.sam', './Files/multi_fasta_SAM/3389_SAM/Sample2_cap.sam', './Files/multi_fasta_SAM/3389_SAM/Sample5_pen.sam', './Files/multi_fasta_SAM/3389_SAM/Sample4_erm.sam', './Files/multi_fasta_SAM/4206_SAM/Sample2_blunt.sam', './Files/multi_fasta_SAM/4206_SAM/Sample6_dual.sam', './Files/multi_fasta_SAM/4206_SAM/Sample1_erm.sam', './Files/multi_fasta_SAM/4206_SAM/Sample3_tuf.sam', './Files/multi_fasta_SAM/4206_SAM/Sample6_cap.sam', './Files/multi_fasta_SAM/4206_SAM/Sample1_pen.sam', './Files/multi_fasta_SAM/4206_SAM/Sample2_tuf.sam', './Files/multi_fasta_SAM/4206_SAM/Sample4_blunt.sam', './Files/multi_fasta_SAM/4206_SAM/Sample3_blunt.sam', './Files/multi_fasta_SAM/4206_SAM/Sample2_erm.sam', './Files/multi_fasta_SAM/4206_SAM/Sample3_pen.sam', './Files/multi_fasta_SAM/4206_SAM/Sample4_cap.sam', './Files/multi_fasta_SAM/4206_SAM/Sample5_blunt.sam', './Files/multi_fasta_SAM/4206_SAM/Sample1_dual.sam', './Files/multi_fasta_SAM/4206_SAM/Sample2_pen.sam', './Files/multi_fasta_SAM/4206_SAM/Sample3_erm.sam', './Files/multi_fasta_SAM/4206_SAM/Sample5_cap.sam', './Files/multi_fasta_SAM/4206_SAM/Sample1_tuf.sam', './Files/multi_fasta_SAM/4206_SAM/Sample4_tuf.sam', './Files/multi_fasta_SAM/4206_SAM/Sample6_erm.sam', './Files/multi_fasta_SAM/4206_SAM/Sample6_blunt.sam', './Files/multi_fasta_SAM/4206_SAM/Sample5_tuf.sam', './Files/multi_fasta_SAM/4206_SAM/Sample6_pen.sam', './Files/multi_fasta_SAM/4206_SAM/Sample1_cap.sam', './Files/multi_fasta_SAM/4206_SAM/Sample4_dual.sam', './Files/multi_fasta_SAM/4206_SAM/Sample5_dual.sam', './Files/multi_fasta_SAM/4206_SAM/Sample1_blunt.sam', './Files/multi_fasta_SAM/4206_SAM/Sample3_cap.sam', './Files/multi_fasta_SAM/4206_SAM/Sample3_dual.sam', './Files/multi_fasta_SAM/4206_SAM/Sample2_dual.sam', './Files/multi_fasta_SAM/4206_SAM/Sample5_erm.sam', './Files/multi_fasta_SAM/4206_SAM/Sample4_pen.sam', './Files/multi_fasta_SAM/4206_SAM/Sample6_tuf.sam', './Files/multi_fasta_SAM/4206_SAM/Sample2_cap.sam', './Files/multi_fasta_SAM/4206_SAM/Sample5_pen.sam', './Files/multi_fasta_SAM/4206_SAM/Sample4_erm.sam']\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "sams = glob.glob(\"./Files/multi_fasta_SAM/*/*.sam\")\n",
    "#sams = glob.glob('*.py')\n",
    "print(sams)\n",
    "print(len(sams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4483 SAM files - DOWNLOAD US .zip',\n",
       " '4483_SAM',\n",
       " '3673_SAM',\n",
       " '.DS_Store',\n",
       " '3936_SAM',\n",
       " '3673 SAM files - DOWNLOAD US .zip',\n",
       " '3389 SAM files - DOWNLOAD US .zip',\n",
       " '3936 SAM files - DOWNLOAD US .zip',\n",
       " '4206 SAM files - DOWNLOAD US .zip',\n",
       " '3389_SAM',\n",
       " '4206_SAM']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.listdir(\"./Files/multi_fasta_SAM/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the script you should get a tabular file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><h1>Monday April 29 - </h1></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #40E0D0;\">GFF files</span>\n",
    "\n",
    "1. Login Galaxy\n",
    "2. Load the fasta files \n",
    "3. Search for <a ref = \"https://www.youtube.com/watch?v=54ECEqJwYz4\">Prokka (Prokaryotic Genome annotation)</a> on the right hand side.\n",
    "4. Under the section 'Contigs to annotate' upload fasta file or reference files already uploaded\n",
    "    - NC_007795.1 (parent strain)\n",
    "4. Run the tool\n",
    "5. Output should appear in histories in about 15 minutes\n",
    "6. next step is to <a ref = \"https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_000013425.1/\">look up</a> the other strains\n",
    "    - NCTC 8325 (NC_007795.1â€”HG003 parent strain) \n",
    "    - USA300-TCH1516 (NC_010079.1)\n",
    "    - MSSA476 (NC_002953.3)\n",
    "    - MW2 (NC_003929.1) //  <span style=\"color: red;\">since the original was not available I used NC_003923.1\n",
    "    - MRSA252 (NC_002952.2) </a>\n",
    "7. Click on FTP and find the gff table\n",
    "8. Make a prot table with both Prokka and pubically available gff files..    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prot table code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Goal: Take gff output from Prokka and make .prot_table required input for TRANSIT Gumbel. \n",
    "\n",
    "# # Packages\n",
    "import glob\n",
    "\n",
    "# # Function\n",
    "def make_prot_table(gff):\n",
    "\tinput = open(gff,'r')\n",
    "\toutput = open(gff[:-3]+\"prot_table\",'w')\n",
    "\tfor line in input.readlines(): \n",
    "\t\tif line.startswith(\"##FASTA\"):\n",
    "\t\t\tbreak\n",
    "\t\telif not line.startswith(\"#\"):\n",
    "\t\t\tinfo = line.split(\"\\t\")\n",
    "\t\t\tif info[2] != 'repeat_region':\n",
    "\t\t\t\tstart = info[3]\n",
    "\t\t\t\tstop = info[4]\n",
    "\t\t\t\tstrand = info[6]\n",
    "\t\t\t\tdetails = info[-1].split(';')\n",
    "\t\t\t\tdetdict = {}\n",
    "\t\t\t\tfor d in details: \n",
    "\t\t\t\t\tdetdict[d.split(\"=\")[0]]=d.split(\"=\")[1]\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\ttag = detdict[\"ID\"]\n",
    "\t\t\t\texcept: print(line)\n",
    "\t\t\t\tif \"Name\" in detdict: \n",
    "\t\t\t\t\tgene = detdict[\"Name\"]\n",
    "\t\t\t\telse: gene = '-'\n",
    "\t\t\t\tprod = detdict[\"product\"].rstrip()\n",
    "\t\t\t\tprodlen = int((int(stop)-int(start))/3)\n",
    "\t\t\t\tfor thing in [prod,start,stop,strand,prodlen,0,0,gene,tag]:\n",
    "\t\t\t\t\toutput.write(str(thing)+'\\t')\n",
    "\t\t\t\toutput.write('-\\n')\n",
    "# # RUN\n",
    "if __name__==\"__main__\": \n",
    "\tgffs = glob.glob(\"~/Dropbox/Breeya_rotation/Files/gff_files/*.gff3\")\n",
    "\tfor g in gffs: \n",
    "\t\tprint(g)\n",
    "\t\tmake_prot_table(g)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Files/gff_files/Galaxy4556-[Prokka_on_data_23__gff].gff3', './Files/gff_files/Galaxy4520-[Prokka_on_data_26__gff].gff3', './Files/gff_files/Galaxy4532-[Prokka_on_data_25__gff].gff3', './Files/gff_files/Galaxy4568-[Prokka_on_data_1819__gff].gff3', './Files/gff_files/Galaxy4544-[Prokka_on_data_24__gff].gff3']\n",
      "./Files/gff_files/Galaxy4556-[Prokka_on_data_23__gff].gff3\n",
      "./Files/gff_files/Galaxy4520-[Prokka_on_data_26__gff].gff3\n",
      "./Files/gff_files/Galaxy4532-[Prokka_on_data_25__gff].gff3\n",
      "./Files/gff_files/Galaxy4568-[Prokka_on_data_1819__gff].gff3\n",
      "./Files/gff_files/Galaxy4544-[Prokka_on_data_24__gff].gff3\n"
     ]
    }
   ],
   "source": [
    "gffs = glob.glob(\"./Files/gff_files/*.gff3\")\n",
    "print((gffs))\n",
    "for g in gffs: \n",
    "    print(g)\n",
    "    make_prot_table(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print (cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Create TA site files (runs on all fastas in directory) `python findTASites.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_010079.1_USA300-TCH1516_sequence.fasta', '/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_007795.1_parent strain_sequence.fasta', '/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_002953.3_MSSA476_sequence.fasta', '/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_003923.1_MW2_sequence.fasta', '/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_002952.2_MRSA252_sequence.fasta']\n",
      "/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_010079.1_USA300-TCH1516_sequence.fasta\n",
      "/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_007795.1_parent strain_sequence.fasta\n",
      "/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_002953.3_MSSA476_sequence.fasta\n",
      "/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_003923.1_MW2_sequence.fasta\n",
      "/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/NC_002952.2_MRSA252_sequence.fasta\n"
     ]
    }
   ],
   "source": [
    "# Goal: Make a list of the TA sites in a nucleotide fasta file\n",
    "\n",
    "import glob \n",
    "\n",
    "def find_tas(fasta):\n",
    "\tfile = open(fasta,'r')\n",
    "\tout=open(fasta[:-6]+'_TASites.txt','w')\n",
    "\tout.write(\";PatID\\tStrand\\tPattern\\tSeqID\\tStart\\tEnd\\tmatching_seq\\tScore\\n\")\n",
    "\tct = 0\n",
    "\tlooking = False\n",
    "\tfor line in file.readlines():\n",
    "\t\tif line.startswith('>'):\n",
    "\t\t\tacc = line.split(' ')[0][1:]\n",
    "\t\telse: \n",
    "\t\t\tfor nt in line:\n",
    "\t\t\t\tif nt != '\\n':\n",
    "\t\t\t\t\tct+=1\n",
    "\t\t\t\t\tif nt == 'T':\n",
    "\t\t\t\t\t\tlooking = True\n",
    "\t\t\t\t\telif looking and nt != 'A':\n",
    "\t\t\t\t\t\tlooking = False\n",
    "\t\t\t\t\telif looking and nt == 'A':\n",
    "\t\t\t\t\t\tlooking = False\n",
    "\t\t\t\t\t\tout.write('\\t'.join(['TA','D','TA',acc,str(ct-1),str(ct),'TA','1'])+'\\n')\n",
    "\t\t\t\t\n",
    "# # RUN\n",
    "if __name__==\"__main__\": \n",
    "\tfastas = glob.glob(\"/Users/tailob/Desktop/jax/repositories/tnseq-meta-integration/Files/fasta_files/*.fasta\")\n",
    "\tfor f in fastas: \n",
    "\t\tprint(f)\n",
    "\t\tfind_tas(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "./Files/fasta_files/NC_010079.1_USA300-TCH1516_sequence.fasta\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_TASites' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m gffs: \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(g)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43m_TASites\u001b[49m\u001b[38;5;241m.\u001b[39mtxt(g)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_TASites' is not defined"
     ]
    }
   ],
   "source": [
    "gffs = glob.glob(\"./Files/fasta_files/*.fasta\")\n",
    "print((fastas))\n",
    "for g in gffs: \n",
    "    print(g)\n",
    "    _TASites.txt(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/tailob/Desktop/jax/repositories/tnseq-meta-integration\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Essential Gene Analysis\n",
    "\n",
    "We identified the essential genes using the TRANSIT software Gumbel method (1). The scripts below are those used to convert files so that they could be used with the TRANSIT software and to perform a permutation test to determine which genes have significant fitness differences across strains of *S. aureus*. \n",
    "\n",
    "### Files Needed\n",
    "- __*.tabular__ - The tabular files acquired from processing the FASTQ files (see above).\n",
    "- __*.fasta__ - A chromosome nucleotide fasta for the genome you are mapping to. See paper methods for the NCBI accession numbers for the strains used.\n",
    "- __*.gff__ - A GFF file output from running Prokka (2) on the fasta files.\n",
    "- __make_prot_tables.py__ - A python script that converts the GFF files from Prokka into prot_table files for TRANSIT. \n",
    "- __findTASites.py__ - For each fasta file in the directory, makes a list of all of the TA sites available.\n",
    "- __make_wig.py__ - Makes a wig file recognized by the TRANSIT software from a tabular file and a list of TA sites created using findTASites.py.\n",
    "- __labelWIGs.py__ - Using the master tag list, changes the gene names in the prot_table files into Roary tags that can be compared across all strains. Then it uses these new prot_tables to annotate the genes in the wig files. For this script to work, the prot_tables have to be named just with the name of the strain and the wig filename has to also include the strain. This script works on all prot_tables and wigs in the directory. The annotated WIGs are saved as csv files.  \n",
    "- __MasterTagList.csv__ - A list of gene names and locations from different strains matched up using Roary (3). NCBI tags are also included, matched to the Prokka genes based on location. \n",
    "- __permutation.py__ - Adds together the reads from all annotated wig files for a strain (file name must start with Roary_*Strain* and must be a csv) and then for each pair of strains, performs a permutation test.  \n",
    "\n",
    "### Process\n",
    "1. Create Prot_Tables (runs on all GFFs in directory) `python make_prot_tables.py`\n",
    "2. Create TA site files (runs on all fastas in directory) `python findTASites.py`\n",
    "3. Create wig files (runs on a single fasta-tabular file pair) `python make_wig.py <XXX_TASites.txt> <XXX.tabular>`\n",
    "4. Run TRANSIT (see <https://pythonhosted.org/tnseq-transit/index.html> for more information).\n",
    "5. Make sure names are compatible with labelWIGs.py and permutation.py (see file descriptions above). \n",
    "6. Rename the genes in the Prot_Tables based on the Roary tags. `python labelWIGs.py` \n",
    "7. Perform the permutation test. By comparing the outputs of this script to the TRANSIT outputs, you can determine which differences in gene essentiality identified by TRANSIT are significant.  `python permutation.py`\n",
    "\n",
    "## Identifying Depleted/Enriched/Upregulated Genes in Treated Files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
